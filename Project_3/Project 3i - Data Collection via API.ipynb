{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Requirements:\n",
    "\n",
    "- Using Reddit's API, weâ€™re to collect posts from two subreddits \n",
    "\n",
    "- We'll then use NLP to train a classifier on which subreddit a given post came from. \n",
    "\n",
    "\n",
    "### Problem Statement\n",
    "- Will classification model work effectively when given 2 very similar topics and which classifier to use?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected 2 subreddits posts - GoogleHome (+ve Class) vs AmazonEcho (-ve Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.reddit.com/r/googlehome.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.reddit.com/r/amazonecho.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame().to_csv('googlehome.csv')\n",
    "pd.DataFrame().to_csv('alexa.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leverage on API to download the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/r/amazonecho.json\n",
      "t3_gffwnp\n",
      "3\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_gffwnp&limit=150\n",
      "t3_gb77dr\n",
      "7\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_gb77dr&limit=150\n",
      "t3_g7aag3\n",
      "4\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_g7aag3&limit=150\n",
      "t3_g3t7lg\n",
      "9\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_g3t7lg&limit=150\n",
      "t3_fzqwrw\n",
      "2\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_fzqwrw&limit=150\n",
      "t3_fvi1v7\n",
      "5\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_fvi1v7&limit=150\n",
      "t3_fql4b6\n",
      "5\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_fql4b6&limit=150\n",
      "t3_fmjfry\n",
      "6\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_fmjfry&limit=150\n",
      "t3_filp54\n",
      "9\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_filp54&limit=150\n",
      "t3_fdtzyl\n",
      "3\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_fdtzyl&limit=150\n",
      "None\n",
      "7\n",
      "https://www.reddit.com/r/amazonecho.json\n",
      "t3_gffwnp\n",
      "10\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_gffwnp&limit=150\n",
      "t3_gb77dr\n",
      "9\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_gb77dr&limit=150\n",
      "t3_g7aag3\n",
      "8\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_g7aag3&limit=150\n",
      "t3_g3t7lg\n",
      "8\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_g3t7lg&limit=150\n",
      "t3_fzqwrw\n",
      "7\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_fzqwrw&limit=150\n",
      "t3_fvi1v7\n",
      "2\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_fvi1v7&limit=150\n",
      "t3_fql4b6\n",
      "10\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_fql4b6&limit=150\n",
      "t3_fmjfry\n",
      "3\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_fmjfry&limit=150\n",
      "t3_filp54\n",
      "8\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_filp54&limit=150\n",
      "t3_fdtzyl\n",
      "2\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_fdtzyl&limit=150\n",
      "None\n",
      "4\n",
      "https://www.reddit.com/r/amazonecho.json\n",
      "t3_gffwnp\n",
      "4\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_gffwnp&limit=150\n",
      "t3_gb77dr\n",
      "10\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_gb77dr&limit=150\n",
      "t3_g7aag3\n",
      "2\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_g7aag3&limit=150\n",
      "t3_g3t7lg\n",
      "5\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_g3t7lg&limit=150\n",
      "t3_fzqwrw\n",
      "3\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_fzqwrw&limit=150\n",
      "t3_fvi1v7\n",
      "2\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_fvi1v7&limit=150\n",
      "t3_fql4b6\n",
      "8\n",
      "https://www.reddit.com/r/amazonecho.json?after=t3_fql4b6&limit=150\n",
      "t3_fmjfry\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "posts = []\n",
    "after = None\n",
    "\n",
    "for a in range(30):\n",
    "    if after == None:\n",
    "        current_url = url\n",
    "    else:\n",
    "        current_url = url + '?after=' + after+'&limit=150'\n",
    "    print(current_url)\n",
    "    res = requests.get(current_url, headers={'User-agent': 'Pony Inc 1.0'})\n",
    "    \n",
    "    if res.status_code != 200:\n",
    "        print('Status error', res.status_code)\n",
    "        break\n",
    "    \n",
    "    current_dict = res.json()\n",
    "    current_posts = [p['data'] for p in current_dict['data']['children']]\n",
    "    posts.extend(current_posts)\n",
    "    after = current_dict['data']['after']\n",
    "\n",
    "    print(after)\n",
    "    \n",
    "    # COMPLETE THE CODE!\n",
    "    if a > 0:\n",
    "        prev_posts = pd.read_csv('alexa.csv')\n",
    "        current_df = pd.DataFrame()\n",
    "        \n",
    "    #else:\n",
    "        pd.DataFrame(posts).to_csv('alexa.csv', index = False)\n",
    "\n",
    "    # generate a random sleep duration to look more 'natural'\n",
    "    sleep_duration = random.randint(2,10)\n",
    "    print(sleep_duration)\n",
    "    time.sleep(sleep_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
